{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting Cancer Types Using Machine Learning Techniques"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# # Data Description"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "The dataset consists of gene expression data that is stored in RES format, a commonly used format for gene pattern data. There are a total of 7129 unique gene features in the dataset, with each column representing a different sample.\n",
    "\n",
    "Each gene is assigned numerical values to indicate its expression levels within a specific sample. Additionally, there is a call column that categorizes the gene as Absent (A), Marginal (M), or Present (P) in that particular sample.\n",
    "\n",
    "The dataset is divided into two files: train and test. The train file contains data from 38 samples, while the test file contains data from 34 samples. This adds up to a total of 72 samples in the complete dataset.\n",
    "\n",
    "The dataset focuses on two types of cancer: Acute Myeloid Leukemia (AML) and Acute Lymphocytic Leukemia (ALL). AML affects myeloid cells, which are responsible for producing certain types of white blood cells. ALL is a type of cancer that affects lymphocytes, a crucial type of white blood cell involved in the immune response. (source)\n",
    "\n",
    "Patient Information:\n",
    "The actual file provides information about individual patients, including their unique identifiers and the specific type of cancer they have been diagnosed with (AML or ALL)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing necessary libraries and functions\n",
    "import pandas as pd\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "train = pd.read_csv(r\"Y:\\IIT KGP Class Materials(Y3)\\Sem 5 Study Material\\Application of Machine Learning in Biological Systems\\Asgn2_21IM30013\\data\\data_train.csv\")\n",
    "test = pd.read_csv(r\"Y:\\IIT KGP Class Materials(Y3)\\Sem 5 Study Material\\Application of Machine Learning in Biological Systems\\Asgn2_21IM30013\\data\\data_test.csv\")\n",
    "actual = pd.read_csv(r\"Y:\\IIT KGP Class Materials(Y3)\\Sem 5 Study Material\\Application of Machine Learning in Biological Systems\\Asgn2_21IM30013\\data\\Copy of actual.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## * Data Description "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset comprises gene expression data stored in RES format, a commonly used format for gene pattern data ([more about RES format here](https://www.genepattern.org/file-formats-guide#RES)). The dataset encompasses 7129 distinct gene features, with columns representing various samples.\n",
    "\n",
    "For each gene, the numerical entries denote its expression levels within a given sample. Additionally, an accompanying `call` column indicates whether the gene is classified as Absent (A), Marginal (M), or Present (P) in that particular sample.\n",
    "\n",
    "The dataset is divided into two files:\n",
    "\n",
    "- `train`: Contains data from 38 samples.\n",
    "- `test`: Contains data from 34 samples.\n",
    "\n",
    "This totals to 72 samples in the entire dataset.\n",
    "\n",
    "### Cancer Types\n",
    "\n",
    "The dataset focuses on two types of cancer:\n",
    "\n",
    "1. **Acute Myeloid Leukemia (AML):** AML affects myeloid cells, which are responsible for generating certain types of white blood cells.\n",
    "\n",
    "2. **Acute Lymphocytic Leukemia (ALL):** ALL is a form of cancer that impacts lymphocytes, a crucial type of white blood cell involved in the immune response. ([source](https://www.healthline.com/health/leukemia/aml-vs-all))\n",
    "\n",
    "### Patient Information\n",
    "\n",
    "The `actual` file provides information about individual patients, including their unique identifiers and the specific type of cancer they have been diagnosed with (AML or ALL).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7129, 78) (7129, 70)\n"
     ]
    }
   ],
   "source": [
    "print(train.shape, test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gene Description</th>\n",
       "      <th>Gene Accession Number</th>\n",
       "      <th>1</th>\n",
       "      <th>call</th>\n",
       "      <th>2</th>\n",
       "      <th>call.1</th>\n",
       "      <th>3</th>\n",
       "      <th>call.2</th>\n",
       "      <th>4</th>\n",
       "      <th>call.3</th>\n",
       "      <th>...</th>\n",
       "      <th>29</th>\n",
       "      <th>call.33</th>\n",
       "      <th>30</th>\n",
       "      <th>call.34</th>\n",
       "      <th>31</th>\n",
       "      <th>call.35</th>\n",
       "      <th>32</th>\n",
       "      <th>call.36</th>\n",
       "      <th>33</th>\n",
       "      <th>call.37</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AFFX-BioB-5_at (endogenous control)</td>\n",
       "      <td>AFFX-BioB-5_at</td>\n",
       "      <td>-214</td>\n",
       "      <td>A</td>\n",
       "      <td>-139</td>\n",
       "      <td>A</td>\n",
       "      <td>-76</td>\n",
       "      <td>A</td>\n",
       "      <td>-135</td>\n",
       "      <td>A</td>\n",
       "      <td>...</td>\n",
       "      <td>15</td>\n",
       "      <td>A</td>\n",
       "      <td>-318</td>\n",
       "      <td>A</td>\n",
       "      <td>-32</td>\n",
       "      <td>A</td>\n",
       "      <td>-124</td>\n",
       "      <td>A</td>\n",
       "      <td>-135</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AFFX-BioB-M_at (endogenous control)</td>\n",
       "      <td>AFFX-BioB-M_at</td>\n",
       "      <td>-153</td>\n",
       "      <td>A</td>\n",
       "      <td>-73</td>\n",
       "      <td>A</td>\n",
       "      <td>-49</td>\n",
       "      <td>A</td>\n",
       "      <td>-114</td>\n",
       "      <td>A</td>\n",
       "      <td>...</td>\n",
       "      <td>-114</td>\n",
       "      <td>A</td>\n",
       "      <td>-192</td>\n",
       "      <td>A</td>\n",
       "      <td>-49</td>\n",
       "      <td>A</td>\n",
       "      <td>-79</td>\n",
       "      <td>A</td>\n",
       "      <td>-186</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AFFX-BioB-3_at (endogenous control)</td>\n",
       "      <td>AFFX-BioB-3_at</td>\n",
       "      <td>-58</td>\n",
       "      <td>A</td>\n",
       "      <td>-1</td>\n",
       "      <td>A</td>\n",
       "      <td>-307</td>\n",
       "      <td>A</td>\n",
       "      <td>265</td>\n",
       "      <td>A</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>A</td>\n",
       "      <td>-95</td>\n",
       "      <td>A</td>\n",
       "      <td>49</td>\n",
       "      <td>A</td>\n",
       "      <td>-37</td>\n",
       "      <td>A</td>\n",
       "      <td>-70</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AFFX-BioC-5_at (endogenous control)</td>\n",
       "      <td>AFFX-BioC-5_at</td>\n",
       "      <td>88</td>\n",
       "      <td>A</td>\n",
       "      <td>283</td>\n",
       "      <td>A</td>\n",
       "      <td>309</td>\n",
       "      <td>A</td>\n",
       "      <td>12</td>\n",
       "      <td>A</td>\n",
       "      <td>...</td>\n",
       "      <td>193</td>\n",
       "      <td>A</td>\n",
       "      <td>312</td>\n",
       "      <td>A</td>\n",
       "      <td>230</td>\n",
       "      <td>P</td>\n",
       "      <td>330</td>\n",
       "      <td>A</td>\n",
       "      <td>337</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AFFX-BioC-3_at (endogenous control)</td>\n",
       "      <td>AFFX-BioC-3_at</td>\n",
       "      <td>-295</td>\n",
       "      <td>A</td>\n",
       "      <td>-264</td>\n",
       "      <td>A</td>\n",
       "      <td>-376</td>\n",
       "      <td>A</td>\n",
       "      <td>-419</td>\n",
       "      <td>A</td>\n",
       "      <td>...</td>\n",
       "      <td>-51</td>\n",
       "      <td>A</td>\n",
       "      <td>-139</td>\n",
       "      <td>A</td>\n",
       "      <td>-367</td>\n",
       "      <td>A</td>\n",
       "      <td>-188</td>\n",
       "      <td>A</td>\n",
       "      <td>-407</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 78 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Gene Description Gene Accession Number    1 call    2  \\\n",
       "0  AFFX-BioB-5_at (endogenous control)        AFFX-BioB-5_at -214    A -139   \n",
       "1  AFFX-BioB-M_at (endogenous control)        AFFX-BioB-M_at -153    A  -73   \n",
       "2  AFFX-BioB-3_at (endogenous control)        AFFX-BioB-3_at  -58    A   -1   \n",
       "3  AFFX-BioC-5_at (endogenous control)        AFFX-BioC-5_at   88    A  283   \n",
       "4  AFFX-BioC-3_at (endogenous control)        AFFX-BioC-3_at -295    A -264   \n",
       "\n",
       "  call.1    3 call.2    4 call.3  ...   29 call.33   30 call.34   31 call.35  \\\n",
       "0      A  -76      A -135      A  ...   15       A -318       A  -32       A   \n",
       "1      A  -49      A -114      A  ... -114       A -192       A  -49       A   \n",
       "2      A -307      A  265      A  ...    2       A  -95       A   49       A   \n",
       "3      A  309      A   12      A  ...  193       A  312       A  230       P   \n",
       "4      A -376      A -419      A  ...  -51       A -139       A -367       A   \n",
       "\n",
       "    32 call.36   33 call.37  \n",
       "0 -124       A -135       A  \n",
       "1  -79       A -186       A  \n",
       "2  -37       A  -70       A  \n",
       "3  330       A  337       A  \n",
       "4 -188       A -407       A  \n",
       "\n",
       "[5 rows x 78 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>patient</th>\n",
       "      <th>cancer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>ALL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>ALL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>ALL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>ALL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>ALL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   patient cancer\n",
       "0        1    ALL\n",
       "1        2    ALL\n",
       "2        3    ALL\n",
       "3        4    ALL\n",
       "4        5    ALL"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actual.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['ALL', 'AML'], dtype=object)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actual.cancer.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Manipulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select columns for training and testing\n",
    "train_columns = [str(i) for i in range(1, 39)]\n",
    "test_columns = [str(i) for i in range(39, 73)]\n",
    "\n",
    "# Transpose the dataframes to have rows as samples\n",
    "train = train[train_columns].transpose()\n",
    "test = test[test_columns].transpose()\n",
    "\n",
    "# Add the target value column from 'actual' file\n",
    "train['target'] = list(actual.cancer.iloc[:38])\n",
    "test['target'] = list(actual.cancer.iloc[38:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define train and test sets\n",
    "X_train = train.iloc[:, :-1]\n",
    "y_train = train['target']\n",
    "X_test = test.iloc[:, :-1]\n",
    "y_test = test['target']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Train the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM Model (with different kernels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (rbf kernel): 0.97\n",
      "Accuracy (linear kernel): 0.97\n",
      "Accuracy (poly kernel): 0.97\n",
      "Accuracy (sigmoid kernel): 0.91\n"
     ]
    }
   ],
   "source": [
    "# Define a list of kernel functions\n",
    "kernels = ['rbf', 'linear', 'poly', 'sigmoid']\n",
    "\n",
    "for kernel in kernels:\n",
    "    # Create and train the SVM model\n",
    "    svc_model = SVC(kernel=kernel, C=10)\n",
    "    svc_model.fit(X_train, y_train)\n",
    "    \n",
    "    # Make predictions and calculate accuracy\n",
    "    y_pred = svc_model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    \n",
    "    # Print the accuracy for each kernel\n",
    "    print(f'Accuracy ({kernel} kernel): {accuracy:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.8529411764705882\n"
     ]
    }
   ],
   "source": [
    "randfmodel = RandomForestClassifier(random_state=42)\n",
    "randfmodel.fit(X_train, y_train)\n",
    "\n",
    "print('Accuracy: ', randfmodel.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Network Classification Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 16\u001b[0m\n\u001b[0;32m     13\u001b[0m grid_search \u001b[38;5;241m=\u001b[39m GridSearchCV(nnmodel, param_grid, cv\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, scoring\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# Perform grid search\u001b[39;00m\n\u001b[1;32m---> 16\u001b[0m \u001b[43mgrid_search\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m# Get the best parameters and the best estimator\u001b[39;00m\n\u001b[0;32m     19\u001b[0m best_params \u001b[38;5;241m=\u001b[39m grid_search\u001b[38;5;241m.\u001b[39mbest_params_\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:1151\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1144\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1146\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1147\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1149\u001b[0m     )\n\u001b[0;32m   1150\u001b[0m ):\n\u001b[1;32m-> 1151\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:898\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    892\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[0;32m    893\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[0;32m    894\u001b[0m     )\n\u001b[0;32m    896\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[1;32m--> 898\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    900\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[0;32m    901\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[0;32m    902\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1419\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1417\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[0;32m   1418\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1419\u001b[0m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mParameterGrid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_grid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:845\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    837\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    838\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[0;32m    839\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    840\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m    841\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[0;32m    842\u001b[0m         )\n\u001b[0;32m    843\u001b[0m     )\n\u001b[1;32m--> 845\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    846\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    847\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    848\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    849\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    850\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    851\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    852\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    853\u001b[0m \u001b[43m        \u001b[49m\u001b[43msplit_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    854\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcandidate_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_candidates\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    855\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_and_score_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    856\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    857\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    858\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcandidate_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    859\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    860\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    862\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    863\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    864\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    865\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    866\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    867\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\parallel.py:65\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     60\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     61\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     62\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     63\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     64\u001b[0m )\n\u001b[1;32m---> 65\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\joblib\\parallel.py:1098\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1095\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m   1097\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[1;32m-> 1098\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mretrieve\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1099\u001b[0m \u001b[38;5;66;03m# Make sure that we get a last message telling us we are done\u001b[39;00m\n\u001b[0;32m   1100\u001b[0m elapsed_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_start_time\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\joblib\\parallel.py:975\u001b[0m, in \u001b[0;36mParallel.retrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    973\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    974\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msupports_timeout\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m--> 975\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output\u001b[38;5;241m.\u001b[39mextend(\u001b[43mjob\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    976\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    977\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output\u001b[38;5;241m.\u001b[39mextend(job\u001b[38;5;241m.\u001b[39mget())\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\joblib\\_parallel_backends.py:567\u001b[0m, in \u001b[0;36mLokyBackend.wrap_future_result\u001b[1;34m(future, timeout)\u001b[0m\n\u001b[0;32m    564\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Wrapper for Future.result to implement the same behaviour as\u001b[39;00m\n\u001b[0;32m    565\u001b[0m \u001b[38;5;124;03mAsyncResults.get from multiprocessing.\"\"\"\u001b[39;00m\n\u001b[0;32m    566\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 567\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfuture\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    568\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m CfTimeoutError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    569\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\concurrent\\futures\\_base.py:451\u001b[0m, in \u001b[0;36mFuture.result\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    448\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[0;32m    449\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__get_result()\n\u001b[1;32m--> 451\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_condition\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    453\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n\u001b[0;32m    454\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\threading.py:320\u001b[0m, in \u001b[0;36mCondition.wait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    318\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:    \u001b[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[0;32m    319\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 320\u001b[0m         \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    321\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    322\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Define the parameter grid for grid search\n",
    "param_grid = {\n",
    "    'activation': ['relu', 'tanh'],\n",
    "    'hidden_layer_sizes': [(50,), (100,), (50, 50), (100, 50)],\n",
    "    'alpha': [0.0001, 0.001, 0.01],\n",
    "    'learning_rate': ['constant', 'invscaling', 'adaptive']\n",
    "}\n",
    "\n",
    "# Initialize the MLPClassifier\n",
    "nnmodel = MLPClassifier(random_state=42, early_stopping=True)\n",
    "\n",
    "# Initialize GridSearchCV\n",
    "grid_search = GridSearchCV(nnmodel, param_grid, cv=3, n_jobs=-1, scoring='accuracy')\n",
    "\n",
    "# Perform grid search\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best parameters and the best estimator\n",
    "best_params = grid_search.best_params_\n",
    "best_estimator = grid_search.best_estimator_\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "accuracy = best_estimator.score(X_test, y_test)\n",
    "\n",
    "print(f\"Best Parameters: {best_params}\")\n",
    "print(f\"Test Accuracy: {accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Result Storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Uncomment the lines to store files from the predictions of the above-mentioned models on the test data\n",
    "# # The outputs generated can be found in 'output' folder [Note that the following code doesn't store it in that folder]\n",
    "# pd.DataFrame({'target':y_test,'prediction':svcrbf.predict(X_test)}).to_csv('svm_rcf_preds.csv')\n",
    "# pd.DataFrame({'target':y_test,'prediction':svclin.predict(X_test)}).to_csv('svm_lin_preds.csv')\n",
    "# pd.DataFrame({'target':y_test,'prediction':svcpoly.predict(X_test)}).to_csv('svm_poly_preds.csv')\n",
    "# pd.DataFrame({'target':y_test,'prediction':svcsig.predict(X_test)}).to_csv('svm_sig_preds.csv')\n",
    "# pd.DataFrame({'target':y_test,'prediction':rfmodel.predict(X_test)}).to_csv('random_forest_preds.csv')\n",
    "# pd.DataFrame({'target':y_test,'prediction':nnmodel.predict(X_test)}).to_csv('neural_networks_preds.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM's role in cancer type prediction\n",
    "\n",
    "We used Support Vector Machines (SVMs) to forecast cancer kinds based on RES format gene data in our study. SVMs proved essential in determining the best decision boundary, efficiently differentiating distinct cancer kinds using genetic information.\n",
    "\n",
    "The adaptability of SVMs was proved by the usage of different kernels:\n",
    "\n",
    "- **Linear Kernel**: Effective for linearly separable data.\n",
    "- **RBF Kernel**: Excelled in capturing non-linear relationships in genetic data.\n",
    "- **Polynomial Kernel**: Valuable for representing polynomial decision boundaries.\n",
    "\n",
    "Each kernel was carefully examined. The linear, RBF, and polynomial kernels obtained an amazing 97.06% accuracy. This demonstrates the robustness of SVMs in discriminating between AML and ALL instances based on the gene data presented.\n",
    "\n",
    "Notably, while the sigmoid kernel continues to perform well,achieved a slightly lower accuracy of approximately 91.18%. This indicates that, for our specific dataset and problem, the sigmoid kernel might not be as well-suited as the other kernels. This emphasizes the critical importance of selecting the most appropriate kernel tailored to the data's characteristics.\n",
    "\n",
    "### Handling High-Dimensional Data\n",
    "\n",
    "SVMs excel in scenarios with numerous features, as seen in our study with 7129 features. Here's how SVMs handled this high-dimensional data:\n",
    "\n",
    "1. **Feature Selection**: SVMs find optimal decision boundaries in high-dimensional spaces, crucial for distinguishing cancer types based on genetic data.\n",
    "\n",
    "2. **Margin Maximization**: They maximize the margin, enhancing generalization to new data points.\n",
    "\n",
    "3. **Kernel Trick for Complexity**: Various kernels handle non-linearities in genetic data effectively.\n",
    "\n",
    "4. **Identifying Important Features**: SVMs pinpoint crucial genes for accurate predictions.\n",
    "\n",
    "5. **Effective Generalization**: Despite high dimensionality, SVMs generalize well to new, unseen data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network Regression Analysis\n",
    "\n",
    "We employed neural network regression to predict cancer kinds using gene data in our study. This strategy is critical for the following reasons:\n",
    "\n",
    "- **Complex Relationship Modeling**: In high-dimensional genetic data, neural networks excel in capturing subtle, non-linear relationships. This reveals subtle patterns that are difficult to detect using typical methods.\n",
    "\n",
    "- **Feature Extraction and Abstraction**: Neural networks extract significant characteristics automatically, with the potential to find critical genetic markers for cancer classification.\n",
    "\n",
    "- **Adaptability to High-Dimensional Data**: Neural networks handle large feature sets, as demonstrated with our 7129-feature gene dataset.\n",
    "\n",
    "In order to optimize the neural network parameters, we also used a grid search:\n",
    "\n",
    "- **Grid Search Process**:\n",
    "\n",
    "  This approach iteratively investigates a given hyperparameter grid in order to find the best-performing combination. Hidden layers and neurons per layer are important neural network hyperparameters, activation functions, and regularization terms.\n",
    "  Grid search fine-tunes the model, preventing overfitting and underfitting. Our analysis resulted in an approximately 94.12% accuracy, indicating effective hyperparameter selection for accurate cancer type predictions using the provided gene dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparison between different models\n",
    "\n",
    "Based on gene data, we tested three models for cancer type prediction: neural networks, support vector machines (SVM), and random forest.\n",
    "\n",
    "- **Neural Network Accuracy**: ~94.12%\n",
    "- **SVM Accuracy**: ~97.06%\n",
    "- **Random Forest Accuracy**: ~85.29% (no hyperparameter tuning)\n",
    "\n",
    "## Model Strengths:\n",
    "\n",
    "- **SVM**:\n",
    "  -Works well in three-dimensional spaces.\n",
    "  - Supports both linear and non-linear relationships.\n",
    "  - Resistant to overfitting.\n",
    "- **Neural Networks**:\n",
    "  - Excellent at capturing complex relationships. \n",
    "  - Extracts key features automatically.\n",
    "\n",
    "- **Random Forest**:\n",
    "  - Effectively handles high-dimensional data.\n",
    "  - Provides feature significance.\n",
    "\n",
    "## Model Weaknesses:\n",
    "\n",
    "- **SVM**:\n",
    "  - Can be computationally costly.\n",
    "  - Vulnerable to kernel and hyperparameter changes.\n",
    "\n",
    "- **Neural Networks**:\n",
    "  - Susceptible to overfitting due to insufficient data.\n",
    "  - Extensive computational requirements.\n",
    "\n",
    "- **Random Forest**:\n",
    " - When there are many trees, it can be computationally expensive. \n",
    " - Capturing intricate relationships is limited.\n",
    "\n",
    "## Model Selection:\n",
    "\n",
    "Given our situation, the SVM model with an accuracy of 97.06% is the best choice. It performs effectively in three-dimensional spaces and generalizes nicely. While neural networks worked admirably, they may be computationally demanding. Random Forest could be improved with hyperparameter adjustment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discussion\n",
    "\n",
    "## Broader Implications of Accurate Cancer Type Prediction\n",
    "\n",
    "Accurate cancer type prediction is crucial in clinical practice and medical research. It can:\n",
    "\n",
    "- **Guide Treatment Strategies**: Precise cancer type influences treatment decisions, allowing for more customized therapy and improved patient outcomes.\n",
    "\n",
    "- **Facilitate Early Detection**: Early cancer type identification can lead to more effective and less intrusive therapies.\n",
    "\n",
    "- **Enable Personalized Medicine**: Understanding a tumor's individual genetic traits enables focused therapy with fewer adverse effects.\n",
    "\n",
    "- **Advance Research and Drug Development**: Classification accuracy aids in the identification of prospective pharmacological targets and the development of new medicines.\n",
    "\n",
    "## Real-World Applications\n",
    "\n",
    "The models' performance has some practical applications in real world:\n",
    "\n",
    "- **Clinical Settings**: Doctors can utilize these models to help with their diagnostic procedure, adding a layer of assurance to cancer typing.\n",
    "\n",
    "- **Research Institutes**:Scientists can use these models for genetic investigations, which will speed up oncology research.\n",
    "\n",
    "- **Drug Development**:Accurate cancer typing can help pharmaceutical companies streamline clinical trials and generate more effective treatments.\n",
    "\n",
    "# Conclusion:\n",
    "\n",
    "## Summary of work\n",
    "\n",
    "Following careful consideration, the Support Vector Machine (SVM) was determined to be the best-performing model, with an accuracy of roughly 97.06%. Its accuracy in high-dimensional spaces and robust generalization make it the best choice for cancer type prediction.\n",
    "\n",
    "## Importance of selecting a proper model and tuning:\n",
    "\n",
    "This study emphasizes the need of careful model selection and parameter adjustment in machine learning. The effectiveness of the SVM emphasizes the significance of matching the model to the properties of the data. Furthermore, parameter optimization ensures that the model is fine-tuned for maximum performance.\n",
    "\n",
    "These concerns are critical in the context of cancer prediction for producing clinically relevant results and advancing cancer research and treatment.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
